{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs vs Cat Redux (KT version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/krit/github-projects/fast-ai/courses/deeplearning1/nbs'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verify we are in the nbs directory\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create references to important directories we will use\n",
    "import os, sys\n",
    "current_dir = os.getcwd()\n",
    "LESSON_HOME_DIR = current_dir\n",
    "DATA_HOME_DIR = current_dir+'/data/redux'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "#import modules\n",
    "from utils import *\n",
    "from vgg16 import Vgg16\n",
    "\n",
    "#Instantiate plotting tool\n",
    "#In Jupyter notebooks, you will need to run this command before doing any plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action Plan\n",
    "1. Create validation and sample sets\n",
    "2. Re-arrange image files into their respective directories\n",
    "3. Finetune and train model\n",
    "4. Generate predictions\n",
    "5. Validate predictions\n",
    "6. Submit predictions to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set constants\n",
    "valid_size = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create directories\n",
    "%cd \"$DATA_HOME_DIR\"\n",
    "%mkdir valid\n",
    "%mkdir results\n",
    "%mkdir -p test/unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd $DATA_HOME_DIR/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(valid_size): os.rename(shuf[i], DATA_HOME_DIR + '/valid/' + shuf[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sample sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set constants\n",
    "sample_train_size = 200\n",
    "sample_valid_size = 50\n",
    "sample_test_size = 200\n",
    "\n",
    "#--local\n",
    "# sample_train_size = 16\n",
    "# sample_valid_size = 8\n",
    "# sample_test_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/krit/github-projects/fast-ai/courses/deeplearning1/nbs/data/redux\n"
     ]
    }
   ],
   "source": [
    "#Create directories\n",
    "%cd \"$DATA_HOME_DIR\"\n",
    "%mkdir -p sample/train\n",
    "%mkdir -p sample/test\n",
    "%mkdir -p sample/valid\n",
    "%mkdir -p sample/results\n",
    "%mkdir -p sample/test/unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(sample_train_size): copyfile(shuf[i], DATA_HOME_DIR + '/sample/train/' + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/krit/github-projects/fast-ai/courses/deeplearning1/nbs/data/redux/valid\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(sample_valid_size): copyfile(shuf[i], DATA_HOME_DIR + '/sample/valid/' + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/krit/github-projects/fast-ai/courses/deeplearning1/nbs/data/redux/test\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(sample_test_size): copyfile(shuf[i], DATA_HOME_DIR + '/sample/test/' + shuf[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rearrange image files into their respective directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/krit/github-projects/fast-ai/courses/deeplearning1/nbs/data/redux/sample/train\n",
      "/home/krit/github-projects/fast-ai/courses/deeplearning1/nbs/data/redux/sample/valid\n",
      "/home/krit/github-projects/fast-ai/courses/deeplearning1/nbs/data/redux/train\n",
      "/home/krit/github-projects/fast-ai/courses/deeplearning1/nbs/data/redux/valid\n"
     ]
    }
   ],
   "source": [
    "#Divide cat/dog images into separate directories\n",
    "subpaths = ['/sample/train', '/sample/valid', '/train', '/valid']\n",
    "path_names = ['cats', 'dogs']\n",
    "class_names = ['cat', 'dog']\n",
    "\n",
    "for subpath in subpaths:\n",
    "    %cd $DATA_HOME_DIR$subpath\n",
    "    for i, path in enumerate(path_names):\n",
    "        %mkdir $path\n",
    "        file_name = class_names[i] + '.*.jpg'\n",
    "        %mv $file_name $path/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/krit/github-projects/fast-ai/courses/deeplearning1/nbs/data/redux/test\n",
      "/home/krit/github-projects/fast-ai/courses/deeplearning1/nbs/data/redux/sample/test\n"
     ]
    }
   ],
   "source": [
    "# Create single 'unknown' class for test set and sample/test set\n",
    "%cd $DATA_HOME_DIR/test\n",
    "%mv *.jpg unknown/\n",
    "\n",
    "%cd $DATA_HOME_DIR/sample/test\n",
    "%mv *.jpg unknown/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "\n",
    "#Set path to sample/ path if desired\n",
    "path = DATA_HOME_DIR + '/'\n",
    "#path = DATA_HOME_DIR + '/sample'\n",
    "\n",
    "test_path = path + '/test/'\n",
    "results_path = path + '/results/'\n",
    "train_path = path + '/train/'\n",
    "valid_path = path + '/valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import Vgg16 helper class\n",
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set constants. You can experiment with no_of_epochs to improve the model\n",
    "batch_size = 64\n",
    "#batch_size = 4\n",
    "\n",
    "no_of_epochs = 3\n",
    "#no_of_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finetune the model\n",
    "batches = vgg.get_batches(train_path, batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(valid_path, batch_size=batch_size*2)\n",
    "vgg.finetune(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Not sure if we set this for all fits\n",
    "vgg.model.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latest_weights_filename = None\n",
    "for epoch in range(no_of_epochs):\n",
    "    print \"Running epoch: %d\" % epoch\n",
    "    vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "    latest_weights_filename = 'ft%d.h5' % epoch\n",
    "    vgg.model.save_weights(results_path+latest_weights_filename)\n",
    "print \"Completed %s fit operations\" % no_of_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Predictions\n",
    "\n",
    "Use our new model to make predictions on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches, preds = vgg.test(test_path, batch_size=batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For every image, vgg.test() generates two probabilities\n",
    "#based on the order of directories (cats, dogs)\n",
    "#Column one: cats, column two: dogs\n",
    "print preds[:5]\n",
    "\n",
    "filenames = batches.filenames\n",
    "print filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Verify the column ordering by viewing some images\n",
    "from PIL import Image\n",
    "Image.open(test_path + filenames[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save our test results arrays so we can use them again later\n",
    "save_array(results_path + 'test_preds.dat', preds)\n",
    "save_array(results_path + 'filenames.dat', filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Predictions to Kaggle!\n",
    "\n",
    "Kaggle wants the imageId followed by the probability of the image being a dog. Kaggle uses a metric called [Log Loss](http://wiki.fast.ai/index.php/Log_Loss) to evaluate your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load our test predictions from file\n",
    "preds = load_array(results_path + 'test_preds.dat')\n",
    "filenames = load_array(results_path + 'filenames.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Grab the dog prediction column\n",
    "isdog = preds[:,1]\n",
    "print \"Raw Predictions: \" + str(isdog[:5])\n",
    "print \"Mid Predictions: \" + str(isdog[(isdog < .6) & (isdog > .4)])\n",
    "print \"Edge Predictions: \" + str(isdog[(isdog == 1) | (isdog == 0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Log Loss](http://wiki.fast.ai/index.php/Log_Loss) doesn't support probability values of 0 or 1--they are undefined (and we have many). Fortunately, Kaggle helps us by offsetting our 0s and 1s by a very small value. So if we upload our submission now we will have lots of .99999999 and .000000001 values. This seems good, right?\n",
    "\n",
    "Not so. There is an additional twist due to how log loss is calculated--log loss rewards predictions that are confident and correct (p=.9999,label=1), but it punishes predictions that are confident and wrong far more (p=.0001,label=1). See visualization below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#So to play it safe, we use a sneaky trick to round down our edge predictions\n",
    "#Swap all ones with .95 and all zeros with .05\n",
    "isdog = isdog.clip(min=0.05, max=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extract imageIds from the filenames in our test/unknown directory \n",
    "filenames = batches.filenames\n",
    "ids = np.array([int(f[8:f.find('.')]) for f in filenames])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we join the two columns into an array of [imageId, isDog]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm = np.stack([ids,isdog], axis=1)\n",
    "subm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "submission_file_name = 'submission1.csv'\n",
    "np.savetxt(submission_file_name, subm, fmt='%d,%.5f', header='id,label', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "%cd $LESSON_HOME_DIR\n",
    "FileLink('data/redux/'+submission_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download this file and submit on the Kaggle website or use the Kaggle command line tool's \"submit\" method."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
